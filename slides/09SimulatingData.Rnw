\documentclass[slidestop,compress,mathserif,red]{beamer}
%\documentclass[handout]{beamer}

%\usepackage{beamerthemesplit}
\usepackage{fancyvrb}
\usepackage{graphicx}
\usepackage{gb4e}
\usepackage{qtree}
\usepackage{hyperref}
\usepackage{ulem}

\usepackage{amsmath,amssymb,amsfonts}

\setbeamerfont{page number in head/foot}{size=\large}
\setbeamertemplate{footline}[frame number]

%\setbeamertemplate{footline}%
%{%
%\hfill\insertpagenumber\ of \ref{TotPages}\hspace{.5cm}\vspace{.5cm}
%\hfill\insertpagenumber\ of 28\hspace{.5cm}\vspace{.5cm}
%}%



\mode<presentation>
{
%\usetheme{Singapore}
%\usetheme{Berlin}

%\setbeamercovered{transparent}

}


%\mode<handout>
%{
%\usepackage{pgfpages}
%\pgfpagesuselayout{4 on 1}[a4paper,landscape,border shrink=5mm]
%}


\usetheme{Montpellier}
%\usecolortheme{beetle}
%\usecolortheme{seagull}
\usecolortheme{lily}

\title[Lecture 6]{Introduction to statistics: Simulating data}

\author{Shravan Vasishth}

\institute{Universit\"at Potsdam\\
vasishth@uni-potsdam.de\\
http://www.ling.uni-potsdam.de/$\sim$vasishth
}

\date{\today}

\addtobeamertemplate{navigation symbols}{}{ \hspace{1em}    \usebeamerfont{footline}%
    \insertframenumber / \inserttotalframenumber }

\begin{document}
\maketitle



<<setup,include=FALSE,cache=FALSE>>=
library(knitr)
library(coda)

# set global chunk options, put figures into folder
options(replace.assign=TRUE,show.signif.stars=FALSE)
opts_chunk$set(fig.path='figures/figure-', fig.align='center', fig.show='hold')
options(replace.assign=TRUE,width=75)
opts_chunk$set(dev='postscript')
#library(rstan)
#set.seed(9991)
# save workspace image, if you want
#the.date <- format(Sys.time(), "%b%d%Y")
#save.image(file=paste0("homework01-",the.date,".RData")
@



\section{Introduction}

\begin{frame}[fragile]\frametitle{Why simulation  is important}

We will need to  simulate  data to

\begin{itemize}
\item Understand the power properties of our experiment design. This  is important for
\begin{itemize}
\item deciding on sample sizes needed
\item deciding whether we are in a Type M error situation when we get a significant result (can we take the sig.\ result seriously?). 
\end{itemize}
\item Understand which parameters can in principle be recovered under repeated sampling (model selection)
\end{itemize}

\end{frame}

\begin{frame}[fragile]\frametitle{Two simulation scenarios}

We will consider two scenarios:

\begin{itemize}
\item Between-subject designs: This is  just to get you used to simulation. We rarely use this in practice.
\item Within-subject  designs: This  is where all the  interesting action is for us, as we will almost always run repeated measures designs.
\end{itemize}

\end{frame}

\section{Between-subject designs: Simulating  data}

\begin{frame}[fragile]\frametitle{Between-subjects example}

\begin{itemize}
\item
Suppose we have reading time data in milliseconds from 10 subjects who see subject relative clause sentences, and a *different* set of 10 subjects who see object relative clauses. 
\item
Assume that (a) the standard deviation is 300 ms, (b) the true subject relative reading time is 700 ms and (c) the true object relative reading time is 750 ms. 
\item
Thus, the true difference between subject relatives and object relatives is 50 ms. \end{itemize}

How to simulate such data?
\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example}


Create a simulated data-set like this:

Take 10 samples from $Normal(\mu=700,\sigma=300)$

Take 10 samples from $Normal(\mu=750,\sigma=300)$

Create a data frame by adding a subject id.
\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example}

<<>>=
sr<-rnorm(10,mean=700,sd=300)
or<-rnorm(10,mean=750,sd=300)
subj<-1:20
cond<-rep(c("sr","or"),each=10)
sim_dat<-data.frame(subj=subj,cond=cond,rt=c(sr,or))
head(sim_dat)
@

\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example}

Question: How can we repeatedly generate such data?

Answer: write a function (I set some default values here).

<<>>=
betwsubj_simdat<-function(n=10,## no. subjs in each cond.
                          mean1=700,stddev=300,
                          mean2=750){
sr<-rnorm(n,mean=mean1,sd=stddev)
or<-rnorm(n,mean=mean2,sd=stddev)
subj<-1:(2*n)
cond<-factor(rep(c("sr","or"),each=n))
sim_dat<-data.frame(subj=subj,cond=cond,rt=c(sr,or))
sim_dat
}
@

\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example}

Now you can repeatedly generate simulated data:

<<>>=
for(i in 1:100){
  sim_dat<-betwsubj_simdat()
}
@

Why would you want to do that? For power analysis, and to check if our model recovers the parameters  correctly under repeated runs of the experiment (with new simulated subjects each time).

\end{frame}

\subsection{Power analysis in a between-subjects design}

\begin{frame}[fragile]\frametitle{Between-subjects example of power analysis}

Analytically:

<<>>=
round(power.t.test(delta=50,n=10,
             sd=300,type="two.sample",
             alternative="two.sided",
             strict=TRUE)$power,3)
@


\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example of power analysis}

Using simulation:

<<cache=TRUE>>=
nsim<-100000
## critical t-value:
crit_t<- qt(0.975,df=18)
## observed t-values:
obs_t<-rep(NA,nsim)

for(i in 1:nsim){
sim_dat<-betwsubj_simdat()
obs_t[i]<-t.test(rt~cond,paired=FALSE,sim_dat)$statistic
}
@

\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example of power analysis}

<<>>=
pow<-mean(abs(obs_t)>abs(crit_t))
round(pow,2)
@

Lesson learnt: for simple between-subject designs, you can use the analytical approach  or simulation.

\end{frame}

\subsection{Using linear models for between-subjects designs}

\begin{frame}[fragile]\frametitle{Between-subjects example using linear models}

Next, we will learn how to compute power using simulation in \textbf{between}-subjects designs using the linear modeling framework (as opposed to the t.test)

After that, will learn how to compute power using simulation in \textbf{within}-subjects designs using t.test and lmer.

\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example using linear models}

Notice that the default contrast coding is 0,1 treatment coding:

<<>>=
sim_dat<-betwsubj_simdat()
contrasts(sim_dat$cond)
@

\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example using linear models}

Recode  to sum contrasts:

<<>>=
## Method 1:
contrasts(sim_dat$cond)<-contr.sum(2)
contrasts(sim_dat$cond)
##  Method 2: (my personal preference)
sim_dat$rctyp<-ifelse(sim_dat$cond=="or",1,-1)
@

\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example using linear models}

Recall that the two-sample t-test (and ANOVA) and the linear model are exactly the same thing:

<<>>=
##  these are all the same test:
t.test(rt~cond,paired=FALSE,sim_dat)$statistic
@

\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example using linear models}

<<>>=
anova(m0<-lm(rt~cond,sim_dat))
@

\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example using linear models}

<<>>=
summary(m0<-lm(rt~cond,sim_dat))
@

\end{frame}


\begin{frame}[fragile]\frametitle{Between-subjects example using linear models}

We can write the linear model as follows. 

For every row i in the data frame dat above, the reading time rt is generated from a model where the contrast coding for the condition column in the i-th row of the data is either -1 or +1, depending on whether we are looking at subject or object relatives. $\varepsilon \sim Normal(0,300)$.

\begin{equation}
rt_i = 725 + 25 \times cond_i + \varepsilon_i
\end{equation}

Now, for the first 10 rows of the data frame, we have only SRs, which are coded -1, and for the second 10 rows, we have only ORs, which are coded +1.

\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example using linear models}

So, the above definition of the linear model is basically expressing how the reading time rt in each row in the data frame is assumed to be generated:

\tiny
\begin{tabular}{rrr}
row &  Intercept & slope + error \\ 
1 & 725$\times$ 1 & +25$\times$ (-1) + $\varepsilon_1$ \\ 
  2 & 725$\times$ 1 & +25$\times$(-1)  + $\varepsilon_2$ \\ 
  3 & 725$\times$ 1 & +25$\times$(-1) + $\varepsilon_3$\\ 
  4 & 725$\times$ 1 & +25$\times$(-1) + $\varepsilon_4$ \\ 
  5 & 725$\times$ 1 & +25$\times$(-1) + $\varepsilon_5$ \\ 
  6 & 725$\times$ 1 & +25$\times$(-1) + $\varepsilon_6$ \\ 
  7 & 725$\times$ 1 & +25$\times$(-1) + $\varepsilon_7$ \\ 
  8 & 725$\times$ 1 & +25$\times$(-1) + $\varepsilon_8$ \\ 
  9 & 725$\times$ 1 & +25$\times$(-1) + $\varepsilon_9$ \\ 
  10 & 725$\times$ 1 & +25$\times$(-1) + $\varepsilon_{10}$ \\ 
  11 & 725$\times$ 1 & +25$\times$(+1) + $\varepsilon_{11}$ \\ 
  12 & 725$\times$ 1 & +25$\times$(+1) + $\varepsilon_{12}$ \\ 
  13 & 725$\times$ 1 & +25$\times$(+1) + $\varepsilon_{13}$ \\ 
  14 & 725$\times$ 1 & +25$\times$(+1) + $\varepsilon_{14}$ \\ 
  15 & 725$\times$ 1 & +25$\times$(+1) + $\varepsilon_{15}$ \\ 
  16 & 725$\times$ 1 & +25$\times$(+1) + $\varepsilon_{16}$ \\ 
  17 & 725$\times$ 1 & +25$\times$(+1) + $\varepsilon_{17}$ \\ 
  18 & 725$\times$ 1 & +25$\times$(+1) + $\varepsilon_{18}$ \\ 
  19 & 725$\times$ 1 & +25$\times$(+1) + $\varepsilon_{19}$ \\ 
  20 & 725$\times$ 1 & +25$\times$(+1) + $\varepsilon_{20}$ \\ 
\end{tabular}

\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example using linear models}

The model m0 is giving us an estimate of the adjustment to the grand mean needed to obtain OR or SR processing cost (700$\pm$ 25). $\varepsilon$ is a random variable with pdf Normal(0,300), and is responsible for the noisiness (variability) in the data.

You can decide whether to reject the null hypothesis in model m0 by looking at the p-value. Recall that the null hypothesis is that OR and SR processing cost has no difference: $H_0: \mu_{SR}-\mu_{OR} = 0$. Here is how you extract the p-value:

<<>>=
summary(m0)$coefficients
## get the second row and fourth column of the output:
summary(m0)$coefficients[2,4]
@

\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example using linear models}

You can now do a power analysis of the above experiment design using the linear modeling framework instead of the t-test. Here is how to do it:


<<cache=TRUE>>=
nsim<-10000
pvals<-rep(NA,nsim)
for(i in 1:nsim){
## create random data
## fit linear model
## extract p-value and save in pvals vector
}
## check proportion of times the pvals are less 
## than 0.05. That's your power. 
@

Stop now and try to do this yourself before moving to the next slide.

\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects example using linear models}


<<cache=TRUE>>=
nsim<-10000
pvals<-rep(NA,nsim)
for(i in 1:nsim){
 sim_dat<-betwsubj_simdat()
 m<-lm(rt~cond,sim_dat)
 pvals[i]<-summary(m)$coefficients[2,4]
}
round(mean(pvals<0.05),2)
@


\end{frame}

\subsection{Checking parameter recover in between-subjects designs}

\begin{frame}[fragile]\frametitle{Between-subjects parameter recovery}

We can also check whether the model can recover the true parameterrs under repeated sampling.

This is an important check of the model's validity; this isn't normally  done  in frequentist courses, but it's a very important and useful tool for model selection, as you will soon see. 

<<cache=TRUE>>=
nsim<-10000
params<-matrix(rep(NA,nsim*3),ncol = 3)

for(i in 1:nsim){
  sim_dat<-betwsubj_simdat()
  m<-lm(rt~cond,sim_dat)
  params[i,c(1,2)]<-summary(m)$coefficients[,1]
  params[i,3]<-summary(m)$sigma
}
@

\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects parameter recovery}

Parameter recovery is pretty good:

<<fig.height=4,echo=FALSE>>=
op<-par(mfrow=c(1,3),pty="s")
hist(params[,1],main="b0")
abline(v=725)
hist(params[,2],main="b1")
abline(v=25)
hist(params[,3],main="sigma")
abline(v=300)
@

\end{frame}

\begin{frame}[fragile]\frametitle{Between-subjects parameter recovery}

What this good parameter recovery is telling us is that the model can in principle provide accurate estimates  of the true parameter values,  under repeated sampling.

Later you  will see examples of models  that fail to achieve this, for some abstract parameters.

\end{frame}

\section{Within-subject designs: Simulating data}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}

Now suppose we have a \textbf{total} of 10 subjects, and we show each subject SRs and ORs once each. Now the subject id's become important!

\end{frame}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}

This is how we could try to generate data now:

<<>>=
## number of subjects
n<-10
sr<-round(rnorm(n,mean=700,sd=300))
or<-round(rnorm(n,mean=750,sd=300))
subj<-rep(1:n,2)
cond<-factor(rep(c("sr","or"),each=n))
sim_dat<-data.frame(subj=subj,cond=cond,rt=c(sr,or))
contrasts(sim_dat$cond)<-contr.sum(2)
@

\end{frame}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}

<<>>=
head(sim_dat)
@

\end{frame}
\begin{frame}[fragile]\frametitle{Generating within-subjects data}

Notice that the subject column now repeats the subject id from 1 to n (whatever n is) for SRs and ORs. The total number of subjects is a total of n now, not $2\times n$ like before.

But these generated data do not reflect the fact that we have within-subjects data! The reason: we are incorrectly assuming that SR and OR reading times are independent! The SR and OR data are paired and therefore dependent because they involve the same subjects.

How to induce dependency in the SR and OR data? 

\end{frame}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}


Let us start by assuming that \textbf{each subject has a different true grand mean processing time}. We will use this assumption to induce a dependency.

One way to encode the assumption that each subject has a different processing time is to assume that 

\begin{itemize}
\item some subjects have mean processing time that is greater than the grand mean 725
\item other subjects have a mean processing time that is smaller than 725
\item some subjects have a mean processing time that is the same as 725
\end{itemize}

\end{frame}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}

We can generate random adjustments to the grand mean of 725 by subject by creating a vector of n scores from a random variable that has mean 0 and some standard deviation (I assume 200 here for illustration):

<<>>=
## grand mean processing cost of each subject:
subject_adj<-round(rnorm(n,mean=0,sd=200))
subject_adj
@

Here, if a subject has a value of 0 in the by-subject adjustments, this implies that the true grand mean reading time of the subject is 725 ms.

\end{frame}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}

Now we see that some subjects are faster than 725 ms and some are slower:

<<>>=
round(725+subject_adj)
@

\end{frame}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}

Now we can generate within subjects data as follows:

<<>>=
## create sum coded condition vector:
cond<-rep(c(-1,1),each=n)
rt <- round(725 + rep(subject_adj,2) + 
              25 * cond + rnorm(n*2,0,200))
@

\end{frame}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}

Next, we replace the rt column in our incorrect data frame sim\_dat with this new corrected rt data, which is now coming from a within-subjects design.

<<>>=
## put in new RTs into data frame:
sim_dat$rt<-rt
head(sim_dat)
@

\end{frame}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}

This data can be (in fact, it *must* be) analyzed using the paired t-test!

\end{frame}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}


<<>>=
t.test(rt~cond,sim_dat,paired=TRUE,var.equal=TRUE)
@

\end{frame}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}


Recall that the same model can be fit using the linear mixed model with varying intercepts:

<<>>=
library(lme4)
m1<-lmer(rt~cond+(1|subj),sim_dat,
control=lmerControl(calc.derivs=FALSE))
@

\end{frame}


\begin{frame}[fragile]\frametitle{Generating within-subjects data}

\tiny
<<>>=
summary(m1)
@

\end{frame}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}

The term $(1|subj)$ in the lmer call above refers to the by-subject adjustment to the grand mean that we did above when generating the data.

\end{frame}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}


Now compute power for this within-subjects design using the paired t-test.

Hint: you can keep creating a new vector of data like this, and overwrite the rt column in the data frame sim\_dat:

<<>>=
sim_dat$rt <- round(725 + rep(subject_adj,2) + 
                      25 * cond + 
                      rnorm(2*n,0,200))
@

Then you can do a paired t-test:

\end{frame}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}

<<>>=
t.test(rt~cond,sim_dat,paired=TRUE,var.equal=TRUE)
@

\end{frame}

\begin{frame}[fragile]\frametitle{Generating within-subjects data}


<<cache=TRUE>>=
nsim<-1000
pvals<-tvals_lmer<-rep(NA,nsim)
for(i in 1:nsim){
  subject_adj<-round(rnorm(n,mean=0,sd=200))
  sim_dat$rt <- round(725 + rep(subject_adj,2) + 
                        25 * cond + rnorm(2*n,0,200))
pvals[i]<-t.test(rt~cond,sim_dat,paired=TRUE)$p.value
tvals_lmer<-summary(lmer(rt~cond+(1|subj),sim_dat,
                         control=lmerControl(calc.derivs=FALSE)))$coefficients[2,3]}
## power using paired t-test:
mean(pvals<0.05)
## using lmer:
mean(abs(tvals_lmer)>2)
@

\end{frame}

\subsection{Checking parameter recover in within-subjects designs}

\begin{frame}[fragile]\frametitle{Within-subjects parameter recovery}

Let's write a function for generating repeated measures data:

<<>>=
withinsubj_simdat<-function(n=10,## no. subjs in each condition
                          b0=725,stddev=300,
                          b1=25,sigma_u0=200){
  u0<-round(rnorm(n,mean=0,sd=200))
  cond<-rep(c(-1,1),each=n)
  subj<-rep(1:n,2)
  rt <- round(b0 + rep(u0,2) + 
                        b1 * cond + rnorm(2*n,0,stddev))
sim_dat<-data.frame(subj=subj,cond=cond,rt=rt)
sim_dat
}
@

\end{frame}

\begin{frame}[fragile]\frametitle{Within-subjects parameter recovery}

Now check if the model recovers the four parameters:

<<cache=TRUE>>=
nsim<-10000
params<-matrix(rep(NA,nsim*4),ncol=4)
for(i in 1:nsim){
  sim_dat<-withinsubj_simdat()
  m<-lmer(rt~cond+(1|subj),sim_dat,
          control=lmerControl(calc.derivs=FALSE))
  params[i,1]<-summary(m)$coefficients[1,1]
  params[i,2]<-summary(m)$coefficients[2,1]
  params[i,3]<-sigma_e<-attr(VarCorr(m),"sc")
  params[i,4]<-sigma_e<-attr(VarCorr(m)$subj,"stddev")
}
@

\end{frame}


\begin{frame}[fragile]\frametitle{Within-subjects parameter recovery}

<<fig.height=4,echo=FALSE>>=
op<-par(mfrow=c(2,2),pty="s")
hist(params[,1],main="b0")
abline(v=725)
hist(params[,2],main="b1")
abline(v=25)
hist(params[,3],main="sigma")
abline(v=300)
hist(params[,4],main="sigma_u0")
abline(v=200)
@


\end{frame}

\begin{frame}[fragile]\frametitle{Within-subjects parameter recovery}

So this linear mixed model is looking pretty OK in terms of parameter recovery.

However, in some cases the $\sigma_{u0}$ parameter is not estimated accurately.   

\end{frame}
\end{document}